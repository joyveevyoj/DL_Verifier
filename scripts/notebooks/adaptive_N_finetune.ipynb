{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615bf572",
   "metadata": {},
   "source": [
    "# Step 1: Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import types\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "# Create dataloaders\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "\n",
    "\n",
    "# Construct path relative to project root\n",
    "_cwd = os.getcwd()\n",
    "if os.path.basename(_cwd) == 'scripts':\n",
    "    # If we're in scripts folder, go up one level\n",
    "    DATASET_PATH = os.path.join(os.path.dirname(_cwd), \"data\", \"verifier_dataset_train.json\")\n",
    "elif os.path.basename(_cwd) == 'notebooks':\n",
    "    # If we're in notebooks folder, go up two levels\n",
    "    DATASET_PATH = os.path.join(os.path.dirname(os.path.dirname(_cwd)), \"data\", \"verifier_dataset_train.json\")\n",
    "else:\n",
    "    # If we're in project root\n",
    "    DATASET_PATH = os.path.join(_cwd, \"data\", \"verifier_dataset_train.json\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f4e35",
   "metadata": {},
   "source": [
    "# Step 2: Tokenizer and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "class Adaptive_N_VerifierDataset(Dataset):\n",
    "    def __init__(self, raw_data_list, tokenizer, max_length=512):\n",
    "        self.samples = []\n",
    "        for entry in raw_data_list:\n",
    "            question = entry['question']\n",
    "            correct_answers_num = entry['correct_answers_num']\n",
    "            total_answers_num = entry['total_answers_num']\n",
    "\n",
    "            # Compute empirical probability (correct rate)\n",
    "            empirical_p = correct_answers_num / total_answers_num if total_answers_num > 0 else 0.0\n",
    "\n",
    "            # Only use the question, no answer/solution\n",
    "            text = f\"Question: {question}\"\n",
    "\n",
    "            # Label is the empirical probability (float between 0.0 and 1.0)\n",
    "            self.samples.append({\"text\": text, \"label\": float(empirical_p)})\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        encodings = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=False\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"],\n",
    "            \"attention_mask\": encodings[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(item[\"label\"], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class VerifierDataset(Dataset):\n",
    "    def __init__(self, raw_data_list, tokenizer, max_length=512):\n",
    "        self.samples = []\n",
    "        for entry in raw_data_list:\n",
    "            question = entry['question']\n",
    "            answers = entry['answers']\n",
    "            labels = entry['answer_labels']\n",
    "            ref_answer = entry[\"reference_answer\"]\n",
    "\n",
    "            # If a reference answer exists, append it to the end and add the corresponding label 1\n",
    "            if ref_answer is not None:\n",
    "                answers = answers + [ref_answer]\n",
    "                labels = labels + [1]\n",
    "            for ans, label in zip(answers, labels):\n",
    "                text = f\"Question: {question}\\nAnswer: {ans}\"\n",
    "                # Label must be float for BCE Loss (0.0 or 1.0)\n",
    "                self.samples.append({\"text\": text, \"label\": float(label)})\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        encodings = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=False\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"],\n",
    "            \"attention_mask\": encodings[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(item[\"label\"], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difficultity classification dataset\n",
    "def probability_to_difficulty_class(prob, num_classes):\n",
    "    \"\"\"\n",
    "    Map a probability value to a difficulty class.\n",
    "\n",
    "    Args:\n",
    "        prob: float between 0.0 and 1.0 (empirical correct rate)\n",
    "        num_classes: int, number of difficulty levels\n",
    "\n",
    "    Returns:\n",
    "        int, class index from 0 to num_classes-1\n",
    "\n",
    "    Examples:\n",
    "        num_classes=2: [0.0, 0.5) → 0, [0.5, 1.0] → 1\n",
    "        num_classes=3: [0.0, 0.33) → 0, [0.33, 0.67) → 1, [0.67, 1.0] → 2\n",
    "        num_classes=4: [0.0, 0.25) → 0, [0.25, 0.5) → 1, [0.5, 0.75) → 2, [0.75, 1.0] → 3\n",
    "    \"\"\"\n",
    "    if prob < 0.0 or prob > 1.0:\n",
    "        raise ValueError(f\"Probability must be between 0.0 and 1.0, got {prob}\")\n",
    "\n",
    "    # Edge case: prob = 1.0 should map to the highest class\n",
    "    if prob == 1.0:\n",
    "        return num_classes - 1\n",
    "\n",
    "    # Map [0, 1) to class indices [0, num_classes-1]\n",
    "    class_idx = int(prob * num_classes)\n",
    "    return class_idx\n",
    "\n",
    "\n",
    "class DifficultyClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for multi-class difficulty classification.\n",
    "    Converts continuous probability labels into discrete difficulty classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, raw_data_list, tokenizer, num_classes=2, max_length=512):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            raw_data_list: List of dicts with 'question', 'correct_answers_num', 'total_answers_num'\n",
    "            tokenizer: Tokenizer instance\n",
    "            num_classes: Number of difficulty levels (default: 2 for easy/hard)\n",
    "            max_length: Max sequence length\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        for entry in raw_data_list:\n",
    "            question = entry['question']\n",
    "            correct_answers_num = entry['correct_answers_num']\n",
    "            total_answers_num = entry['total_answers_num']\n",
    "\n",
    "            # Compute empirical probability (correct rate)\n",
    "            empirical_p = correct_answers_num / total_answers_num if total_answers_num > 0 else 0.0\n",
    "\n",
    "            # Convert probability to difficulty class\n",
    "            difficulty_class = probability_to_difficulty_class(empirical_p, num_classes)\n",
    "\n",
    "            # Only use the question, no answer/solution\n",
    "            text = f\"Question: {question}\"\n",
    "\n",
    "            # Store both the class and the original probability for reference\n",
    "            self.samples.append({\n",
    "                \"text\": text,\n",
    "                \"label\": difficulty_class,\n",
    "                \"prob\": empirical_p  # Keep original for debugging/analysis\n",
    "            })\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        encodings = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=False\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"],\n",
    "            \"attention_mask\": encodings[\"attention_mask\"],\n",
    "            \"labels\": torch.tensor(item[\"label\"], dtype=torch.long)  # long for CE loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff3d4c",
   "metadata": {},
   "source": [
    "# Step 3: Two-Head Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29360f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Two-Head Model Implementation\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Loading base Qwen3Model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# Load ONLY the base transformer (Qwen3Model), not the classifier\n",
    "base_model = AutoModel.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device\n",
    ")\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Apply LoRA to base model\n",
    "print(\"Applying LoRA...\")\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.FEATURE_EXTRACTION,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    ")\n",
    "base_model = get_peft_model(base_model, peft_config)\n",
    "base_model.print_trainable_parameters()\n",
    "\n",
    "# Get hidden size\n",
    "hidden_size = base_model.config.hidden_size\n",
    "\n",
    "# Configuration for head_b\n",
    "NUM_CLASSES = None  # Set to None for probability regression, or n for n-class classification\n",
    "\n",
    "# Manually create two heads\n",
    "head_dtype = base_model.dtype\n",
    "head_a = nn.Linear(hidden_size, 1, bias=False).to(device, dtype=head_dtype)\n",
    "\n",
    "# # Head B: one layer probability regression (1 output) or multi-class classification (n outputs)\n",
    "# if NUM_CLASSES is None:\n",
    "#     head_b = nn.Linear(hidden_size, 1, bias=True).to(device, dtype=head_dtype)\n",
    "#     head_b_mode = \"Probability Regression\"\n",
    "# else:\n",
    "#     head_b = nn.Linear(hidden_size, NUM_CLASSES, bias=True).to(device, dtype=head_dtype)\n",
    "#     head_b_mode = f\"{NUM_CLASSES}-Class Classification\"\n",
    "# Head B: probability regression (1 output) or multi-class classification (n outputs)\n",
    "# print(f\"\\nTwo heads created:\")\n",
    "# print(f\"  Head A (Binary Classification): {head_a}\")\n",
    "# print(f\"  Head B ({head_b_mode}): {head_b}\")\n",
    "# print(f\"  NUM_CLASSES = {NUM_CLASSES}\")\n",
    "if NUM_CLASSES is None:\n",
    "    output_dim = 1\n",
    "    head_b_mode = \"Probability Regression\"\n",
    "else:\n",
    "    output_dim = NUM_CLASSES\n",
    "    head_b_mode = f\"{NUM_CLASSES}-Class Classification\"\n",
    "\n",
    "# Two-layer classifier head with GELU activation and dropout\n",
    "head_b = nn.Sequential(\n",
    "    nn.Linear(hidden_size, hidden_size, bias=True),\n",
    "    nn.GELU(),\n",
    "    nn.LayerNorm(hidden_size),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hidden_size, output_dim, bias=True)\n",
    ").to(device, dtype=head_dtype)\n",
    "\n",
    "print(f\"\\nTwo heads created:\")\n",
    "print(f\"  Head A (Binary Classification): {head_a}\")\n",
    "print(f\"  Head B ({head_b_mode}): 2-layer MLP\")\n",
    "print(f\"    - Layer 1: Linear({hidden_size}, {hidden_size}) + GELU + Dropout(0.1)\")\n",
    "print(f\"    - Layer 2: Linear({hidden_size}, {output_dim})\")\n",
    "print(f\"  NUM_CLASSES = {NUM_CLASSES}\")\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Define forward function\n",
    "# ==============================================================================\n",
    "def two_head_forward(input_ids, attention_mask, head='both'):\n",
    "    \"\"\"\n",
    "    Forward pass for two-head model.\n",
    "\n",
    "    Args:\n",
    "        input_ids: Token IDs\n",
    "        attention_mask: Attention mask\n",
    "        head: 'a', 'b', or 'both'\n",
    "\n",
    "    Returns:\n",
    "        SimpleNamespace with .logits (and .logits_b for 'both')\n",
    "        - Head A: (batch, 1) for binary classification\n",
    "        - Head B: (batch, 1) if NUM_CLASSES is None (probability regression)\n",
    "                  (batch, NUM_CLASSES) if NUM_CLASSES is set (multi-class classification)\n",
    "    \"\"\"\n",
    "    from types import SimpleNamespace\n",
    "\n",
    "    # Get base model outputs\n",
    "    outputs = base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    # Get last hidden state\n",
    "    last_hidden = outputs.last_hidden_state  # (batch, seq_len, hidden_size)\n",
    "\n",
    "    # Mean pooling with masking\n",
    "    if attention_mask is not None:\n",
    "        mask = attention_mask.unsqueeze(-1).float()  # (batch, seq_len, 1)\n",
    "        masked_hidden = last_hidden * mask\n",
    "        summed = masked_hidden.sum(dim=1)  # (batch, hidden_size)\n",
    "        counts = mask.sum(dim=1).clamp(min=1e-9)  # (batch, 1)\n",
    "        pooled = summed / counts\n",
    "    else:\n",
    "        pooled = last_hidden.mean(dim=1)  # (batch, hidden_size)\n",
    "\n",
    "    # # Last-token pooling (respect attention mask)\n",
    "    # seq_lens = attention_mask.sum(dim=1) - 1  # index of last non-padding token\n",
    "    # seq_lens = seq_lens.clamp(min=0)\n",
    "    # last_tokens = last_hidden[torch.arange(last_hidden.size(0)), seq_lens]  # (batch, hidden_size)\n",
    "    # pooled = last_tokens\n",
    "    pooled = pooled.to(head_a.weight.dtype)\n",
    "    # Apply heads\n",
    "    logits_a = head_a(pooled)  # (batch, 1)\n",
    "    logits_b = head_b(pooled)  # (batch, 1)\n",
    "\n",
    "    # Return based on which head(s) requested\n",
    "    if head == 'a':\n",
    "        return SimpleNamespace(logits=logits_a)\n",
    "    elif head == 'b':\n",
    "        return SimpleNamespace(logits=logits_b)\n",
    "    else:  # 'both'\n",
    "        return SimpleNamespace(logits=logits_a, logits_b=logits_b)\n",
    "\n",
    "print(\"\\nTwo-head model ready!\")\n",
    "print(\"Usage: two_head_forward(input_ids, attention_mask, head='a'/'b'/'both')\")\n",
    "print(f\"Note: Change NUM_CLASSES to switch between regression (None) and classification (n)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d469657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Test Two-Head Model\n",
    "# ==============================================================================\n",
    "print(\"Testing Two-Head Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create test input\n",
    "test_text = \"Question: What is 2+2?\"\n",
    "test_inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "test_inputs = {k: v.to(device) for k, v in test_inputs.items()}\n",
    "\n",
    "# Test Head A (Binary Classification)\n",
    "print(\"\\n1. Head A (Binary Classification):\")\n",
    "outputs_a = two_head_forward(**test_inputs, head='a')\n",
    "prob_a = torch.sigmoid(outputs_a.logits)\n",
    "print(f\"   Logit: {outputs_a.logits.item():.4f}\")\n",
    "print(f\"   Probability: {prob_a.item():.4f}\")\n",
    "\n",
    "# Test Head B (Probability Regression or Classification)\n",
    "if NUM_CLASSES is None:\n",
    "    print(\"\\n2. Head B (Probability Regression):\")\n",
    "    outputs_b = two_head_forward(**test_inputs, head='b')\n",
    "    prob_b = torch.sigmoid(outputs_b.logits)\n",
    "    print(f\"   Logit: {outputs_b.logits.item():.4f}\")\n",
    "    print(f\"   Probability: {prob_b.item():.4f}\")\n",
    "else:\n",
    "    print(f\"\\n2. Head B ({NUM_CLASSES}-Class Classification):\")\n",
    "    outputs_b = two_head_forward(**test_inputs, head='b')\n",
    "    print(f\"   Logits shape: {outputs_b.logits.shape}\")\n",
    "    print(f\"   Logits: {outputs_b.logits.squeeze()}\")\n",
    "    probs = torch.softmax(outputs_b.logits, dim=-1)\n",
    "    print(f\"   Class probabilities: {probs.squeeze()}\")\n",
    "    print(f\"   Predicted class: {probs.argmax(dim=-1).item()}\")\n",
    "\n",
    "# Test Both Heads\n",
    "print(\"\\n3. Both Heads:\")\n",
    "outputs_both = two_head_forward(**test_inputs, head='both')\n",
    "print(f\"   Head A Logit: {outputs_both.logits.item():.4f}\")\n",
    "if NUM_CLASSES is None:\n",
    "    print(f\"   Head B Logit: {outputs_both.logits_b.item():.4f}\")\n",
    "else:\n",
    "    print(f\"   Head B Logits: {outputs_both.logits_b.squeeze()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Test Complete! Two-head model working correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c54c7a",
   "metadata": {},
   "source": [
    "# Step 4: (Option1) Two Stage Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Stage headB, p prediction: Train LoRA + Head B (Freeze Head A)\n",
    "# ==============================================================================\n",
    "# Goal: Train the model to predict question difficulty (correct rate)\n",
    "# ==============================================================================\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3 #5e-4\n",
    "DEBUG_SAMPLE_SIZE = None # Set to None for full run\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "print(\"Stage B: Training LoRA + Head B (Head A frozen)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Freeze Head A\n",
    "for param in head_a.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"Head A frozen\")\n",
    "\n",
    "# Load dataset\n",
    "print(\"\\nLoading dataset...\")\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"Error: {DATASET_PATH} not found\")\n",
    "else:\n",
    "    with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "        raw_questions = json.load(f)\n",
    "\n",
    "    if DEBUG_SAMPLE_SIZE:\n",
    "        raw_questions = raw_questions[:DEBUG_SAMPLE_SIZE]\n",
    "\n",
    "    random.seed(42)\n",
    "    random.shuffle(raw_questions)\n",
    "\n",
    "    # 90/10 split\n",
    "    split_idx = int(0.9 * len(raw_questions))\n",
    "    train_questions = raw_questions[:split_idx]\n",
    "    val_questions = raw_questions[split_idx:]\n",
    "\n",
    "    # Create datasets for Head B (question only, predict correct rate)\n",
    "    train_dataset = Adaptive_N_VerifierDataset(train_questions, tokenizer, max_length=256)\n",
    "    val_dataset = Adaptive_N_VerifierDataset(val_questions, tokenizer, max_length=256)\n",
    "\n",
    "    print(f\" Dataset loaded: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
    "\n",
    "# Set up optimizer (only LoRA + head_b parameters)\n",
    "trainable_params = [p for p in base_model.parameters() if p.requires_grad] + \\\n",
    "                     [p for p in head_b.parameters() if p.requires_grad]\n",
    "optimizer = AdamW(trainable_params, lr=LEARNING_RATE)\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_training_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * num_training_steps),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Loss function: BCE for comparing two probabilities (prediction vs empirical)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f\"\\n Optimizer and scheduler ready\")\n",
    "print(f\"  Training params: LoRA + Head B\")\n",
    "print(f\"  Loss function: BCEWithLogitsLoss (cross-entropy)\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Training Loop - Stage B\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "OUTPUT_DIR_STAGEB = \"../../outputs/two_head_stageB\"\n",
    "os.makedirs(OUTPUT_DIR_STAGEB, exist_ok=True)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    base_model.train()\n",
    "    head_b.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass (Head B only)\n",
    "        outputs = two_head_forward(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            head='b'\n",
    "        )\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs.logits.squeeze(-1), batch['labels'].float())\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Track loss\n",
    "        total_train_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    base_model.eval()\n",
    "    head_b.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            outputs = two_head_forward(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                head='b'\n",
    "            )\n",
    "\n",
    "            loss = loss_fn(outputs.logits.squeeze(-1), batch['labels'])\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'base_model_state_dict': base_model.state_dict(),\n",
    "        'head_b_state_dict': head_b.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss,\n",
    "    }\n",
    "    if (epoch + 1) % 3 ==0:\n",
    "        torch.save(checkpoint, os.path.join(OUTPUT_DIR_STAGEB, f'checkpoint_epoch{epoch+1}.pt'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" Stage B Training Complete!\")\n",
    "print(f\"Models saved to: {OUTPUT_DIR_STAGEB}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668355c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Test Stage B Model\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nTesting trained Head B...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "base_model.eval()\n",
    "head_b.eval()\n",
    "\n",
    "# Test with a few examples\n",
    "test_questions = [\n",
    "    \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n",
    "    \"Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\",\n",
    "    \"A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\",\n",
    "    \"Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy.  She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed.  In the afternoon, she gives her chickens another 25 cups of feed.  How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi's flock is 20 chickens?\"\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for q in test_questions:\n",
    "        text = f\"Question: {q}\"\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        outputs = two_head_forward(**inputs, head='b')\n",
    "        predicted_prob = torch.sigmoid(outputs.logits).item()\n",
    "\n",
    "        print(f\"\\nQuestion: {q}\")\n",
    "        print(f\"  Predicted difficulty (probability): {predicted_prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation comparison\n",
    "\n",
    "base_model.eval()\n",
    "head_b.eval()\n",
    "print(\"\\nValidating on 5 examples from val set\")\n",
    "print(\"=\"*60)\n",
    "val_entries = val_questions[:20]  # replace with however you load your validation split\n",
    "for entry in val_entries:\n",
    "    text = f\"Question: {entry['question']}\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits_b = two_head_forward(**inputs, head='b').logits\n",
    "    pred_prob = torch.sigmoid(logits_b).item()\n",
    "    true_prob = entry['correct_answers_num'] / max(entry['total_answers_num'], 1)\n",
    "    print(f\"\\nQuestion: {entry['question']}\")\n",
    "    print(f\"  Predicted difficulty: {pred_prob:.4f}\")\n",
    "    print(f\"  True difficulty:      {true_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765ae40",
   "metadata": {},
   "source": [
    " # (Option2) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef274d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stage: Multi-Class Difficulty Classification Training Setup\n",
    "# ==============================================================================\n",
    "# Goal: Train the model to classify questions into N difficulty levels\n",
    "# ==============================================================================\n",
    "\n",
    "# Configuration\n",
    "NUM_CLASSES = 4  # Number of difficulty levels (2, 3, 4, etc.)\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 2\n",
    "DEBUG_SAMPLE_SIZE = None # Set to None for full dataset\n",
    "\n",
    "print(f\"Classification Training Setup: {NUM_CLASSES}-Class Difficulty\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Freeze Head A (we're only training Head B for classification)\n",
    "for param in head_a.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"✓ Head A frozen\")\n",
    "\n",
    "# Load dataset\n",
    "print(\"\\n✓ Loading dataset...\")\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATASET_PATH}\")\n",
    "\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_questions = json.load(f)\n",
    "\n",
    "if DEBUG_SAMPLE_SIZE:\n",
    "    raw_questions = raw_questions[:DEBUG_SAMPLE_SIZE]\n",
    "    print(f\"  Using {DEBUG_SAMPLE_SIZE} samples for debugging\")\n",
    "\n",
    "# Shuffle and split (90/10)\n",
    "random.seed(42)\n",
    "random.shuffle(raw_questions)\n",
    "split_idx = int(0.9 * len(raw_questions))\n",
    "train_questions = raw_questions[:split_idx]\n",
    "val_questions = raw_questions[split_idx:]\n",
    "\n",
    "# Create classification datasets\n",
    "train_dataset = DifficultyClassificationDataset(\n",
    "    train_questions,\n",
    "    tokenizer,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    max_length=256\n",
    ")\n",
    "val_dataset = DifficultyClassificationDataset(\n",
    "    val_questions,\n",
    "    tokenizer,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "print(f\"✓ Dataset loaded: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
    "\n",
    "# Create dataloaders\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
    "\n",
    "print(f\"✓ DataLoaders ready: {len(train_loader)} train batches, {len(val_loader)} val batches\")\n",
    "\n",
    "# Set up optimizer (LoRA + head_b parameters only)\n",
    "trainable_params = list(base_model.parameters()) + list(head_b.parameters())\n",
    "optimizer = AdamW(trainable_params, lr=LEARNING_RATE)\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_training_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * num_training_steps),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Loss function: CrossEntropy for multi-class classification\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"\\n✓ Training setup complete:\")\n",
    "print(f\"  Model: LoRA + Head B ({NUM_CLASSES} classes)\")\n",
    "print(f\"  Loss: CrossEntropyLoss\")\n",
    "print(f\"  Optimizer: AdamW (lr={LEARNING_RATE})\")\n",
    "print(f\"  Scheduler: Linear warmup (10% steps)\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bcd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Training Loop: Multi-Class Difficulty Classification\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ==================== Training ====================\n",
    "    base_model.train()\n",
    "    head_b.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)  # (batch,) with class indices\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = two_head_forward(input_ids, attention_mask, head='b')\n",
    "        logits = outputs.logits.squeeze(-1) if NUM_CLASSES is None else outputs.logits  # (batch, num_classes)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Track metrics\n",
    "        epoch_loss += loss.item()\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{train_correct/train_total:.4f}'\n",
    "        })\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ==================== Validation ====================\n",
    "    base_model.eval()\n",
    "    head_b.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]  \", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = two_head_forward(input_ids, attention_mask, head='b')\n",
    "            logits = outputs.logits.squeeze(-1) if NUM_CLASSES is None else outputs.logits\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Track accuracy\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} Summary:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        print(f\"  ✓ New best validation accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "    print(\"-\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Complete!\")\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd680a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33bfd4da",
   "metadata": {},
   "source": [
    " # (Option3) Mixed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Mixed Training: Alternating Head A and Head B\n",
    "# ==============================================================================\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "# epoch_ratios = [0.7, 0.5, 0.3, 0.2]  # Ratio of Head A batches per epoch\n",
    "epoch_ratios = [0, 0, 0, 0]  # Ratio of Head A batches per epoch\n",
    "BATCH_SIZE = 20\n",
    "DEBUG_SAMPLE_SIZE = 1000\n",
    "OUTPUT_DIR_MIXED = \"../../outputs/two_head_mixed\"\n",
    "os.makedirs(OUTPUT_DIR_MIXED, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Mixed Training Setup\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load dataset\n",
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_questions = json.load(f)\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(raw_questions)\n",
    "split_idx = int(0.9 * len(raw_questions))\n",
    "if DEBUG_SAMPLE_SIZE:\n",
    "    raw_questions = raw_questions[:DEBUG_SAMPLE_SIZE]\n",
    "    split_idx = int(0.9 * len(raw_questions))\n",
    "\n",
    "train_questions = raw_questions[:split_idx]\n",
    "val_questions = raw_questions[split_idx:]\n",
    "\n",
    "\n",
    "# Create both datasets\n",
    "dataset_a = VerifierDataset(train_questions, tokenizer, max_length=256)  # Head A: binary\n",
    "dataset_b = Adaptive_N_VerifierDataset(train_questions, tokenizer, max_length=256)  # Head B: regression\n",
    "\n",
    "val_dataset_a = VerifierDataset(val_questions, tokenizer, max_length=256)\n",
    "val_dataset_b = Adaptive_N_VerifierDataset(val_questions, tokenizer, max_length=256)\n",
    "\n",
    "print(f\"Head A dataset: {len(dataset_a)} train, {len(val_dataset_a)} val\")\n",
    "print(f\"Head B dataset: {len(dataset_b)} train, {len(val_dataset_b)} val\")\n",
    "\n",
    "# Create dataloaders\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "loader_a = DataLoader(dataset_a, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
    "loader_b = DataLoader(dataset_b, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collator)\n",
    "val_loader_a = DataLoader(val_dataset_a, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
    "val_loader_b = DataLoader(val_dataset_b, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "trainable_params = list(base_model.parameters()) + list(head_a.parameters()) + list(head_b.parameters())\n",
    "optimizer = AdamW(trainable_params, lr=LEARNING_RATE)\n",
    "\n",
    "total_batches = max(len(loader_a), len(loader_b)) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_batches),\n",
    "    num_training_steps=total_batches\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f\"\\n Setup complete\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Epoch ratios (Head A): {epoch_ratios}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "# TensorBoard writer\n",
    "import time\n",
    "import os\n",
    "\n",
    "run_name = time.strftime(\"%Y%m%d-%H%M%S\")   # e.g., \"20250204-153232\"\n",
    "log_dir = os.path.join(OUTPUT_DIR_MIXED, \"logs\", run_name)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "print(f\"TensorBoard logs saved to: {log_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Mixed Training Loop\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting Mixed Training\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Get ratio for this epoch\n",
    "    ratio_a = epoch_ratios[epoch] if epoch < len(epoch_ratios) else epoch_ratios[-1]\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} - Head A ratio: {ratio_a:.2f}\")\n",
    "\n",
    "    # Training phase\n",
    "    base_model.train()\n",
    "    head_a.train()\n",
    "    head_b.train()\n",
    "\n",
    "    # Create iterators\n",
    "    iter_a = iter(loader_a)\n",
    "    iter_b = iter(loader_b)\n",
    "    total_batches = max(len(loader_a), len(loader_b))\n",
    "\n",
    "    total_loss_a = 0\n",
    "    total_loss_b = 0\n",
    "    count_a = 0\n",
    "    count_b = 0\n",
    "\n",
    "    progress_bar = tqdm(range(total_batches), desc=f\"Epoch {epoch+1}\")\n",
    "    global_step = epoch * total_batches  # Global step counter\n",
    "    for _ in progress_bar:\n",
    "        # Decide which head to train this batch\n",
    "\n",
    "        use_head_a = random.random() < ratio_a\n",
    "\n",
    "        if use_head_a:\n",
    "            # Train Head A (freeze Head B)\n",
    "            try:\n",
    "                batch = next(iter_a)\n",
    "            except StopIteration:\n",
    "                iter_a = iter(loader_a)\n",
    "                batch = next(iter_a)\n",
    "\n",
    "            # Freeze Head B parameters\n",
    "            for param in head_b.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in head_a.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            # Move to device and forward\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = two_head_forward(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                head='a'\n",
    "            )\n",
    "            loss = loss_fn(outputs.logits.squeeze(-1), batch['labels'])\n",
    "\n",
    "            total_loss_a += loss.item()\n",
    "            count_a += 1\n",
    "            writer.add_scalar('Loss/batch_a', loss.item(), global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        else:\n",
    "            # Train Head B (freeze Head A)\n",
    "            try:\n",
    "                batch = next(iter_b)\n",
    "            except StopIteration:\n",
    "                iter_b = iter(loader_b)\n",
    "                batch = next(iter_b)\n",
    "\n",
    "            # Freeze Head A parameters\n",
    "            for param in head_a.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in head_b.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            # Move to device and forward\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = two_head_forward(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                head='b'\n",
    "            )\n",
    "            loss = loss_fn(outputs.logits.squeeze(-1), batch['labels'])\n",
    "\n",
    "            total_loss_b += loss.item()\n",
    "            count_b += 1\n",
    "            writer.add_scalar('Loss/batch_b', loss.item(), global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Update progress\n",
    "        progress_bar.set_postfix({\n",
    "            'loss_a': f'{total_loss_a/max(count_a,1):.4f}',\n",
    "            'loss_b': f'{total_loss_b/max(count_b,1):.4f}',\n",
    "            'n_a': count_a,\n",
    "            'n_b': count_b\n",
    "        })\n",
    "\n",
    "    avg_loss_a = total_loss_a / max(count_a, 1)\n",
    "    avg_loss_b = total_loss_b / max(count_b, 1)\n",
    "\n",
    "    # Validation phase\n",
    "    base_model.eval()\n",
    "    head_a.eval()\n",
    "    head_b.eval()\n",
    "\n",
    "    # Unfreeze both for validation (no grad anyway)\n",
    "    for param in head_a.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in head_b.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    val_loss_a = 0\n",
    "    val_loss_b = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader_a:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = two_head_forward(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                head='a'\n",
    "            )\n",
    "            loss = loss_fn(outputs.logits.squeeze(-1), batch['labels'])\n",
    "            val_loss_a += loss.item()\n",
    "\n",
    "        for batch in val_loader_b:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs =  two_head_forward(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                head='b'\n",
    "            )\n",
    "            loss = loss_fn(outputs.logits.squeeze(-1), batch['labels'])\n",
    "            val_loss_b += loss.item()\n",
    "\n",
    "    avg_val_loss_a = val_loss_a / len(val_loader_a)\n",
    "    avg_val_loss_b = val_loss_b / len(val_loader_b)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Complete:\")\n",
    "    print(f\"  Head A - Train: {avg_loss_a:.4f}, Val: {avg_val_loss_a:.4f} ({count_a} batches)\")\n",
    "    print(f\"  Head B - Train: {avg_loss_b:.4f}, Val: {avg_val_loss_b:.4f} ({count_b} batches)\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'base_model_state_dict': base_model.state_dict(),\n",
    "        'head_a_state_dict': head_a.state_dict(),\n",
    "        'head_b_state_dict': head_b.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss_a': avg_loss_a,\n",
    "        'loss_b': avg_loss_b,\n",
    "        'val_loss_a': avg_val_loss_a,\n",
    "        'val_loss_b': avg_val_loss_b,\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(OUTPUT_DIR_MIXED, f'checkpoint_epoch{epoch+1}.pt'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Mixed Training Complete!\")\n",
    "print(f\"Models saved to: {OUTPUT_DIR_MIXED}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5efaf3",
   "metadata": {},
   "source": [
    "# (Option4) Token logic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b0adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import math\n",
    "\n",
    "class MathDifficultyClassifier:\n",
    "    def __init__(self, model_name: str, device: torch.device, num_classes: int = 4):\n",
    "        \"\"\"\n",
    "        A difficulty classifier using letter labels instead of numbers.\n",
    "\n",
    "        Args:\n",
    "            model_name: HuggingFace model name\n",
    "            device: \"cuda\" / \"cpu\"\n",
    "            num_classes: Number of difficulty levels (2, 3, or 4)\n",
    "        \"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=\"auto\",\n",
    "        )\n",
    "\n",
    "        if device is not None:\n",
    "            self.model.to(device)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Define letter labels based on num_classes\n",
    "        if num_classes == 2:\n",
    "            # Binary: Hard, Easy\n",
    "            self.class_labels = [\"h\", \"e\"]  # hard, easy\n",
    "            self.class_names = [\"Hard\", \"Easy\"]\n",
    "        elif num_classes == 3:\n",
    "            # Three levels: Hard, Medium, Easy\n",
    "            self.class_labels = [\"h\", \"m\", \"e\"]  # hard, medium, easy\n",
    "            self.class_names = [\"Hard\", \"Medium\", \"Easy\"]\n",
    "        elif num_classes == 4:\n",
    "            # Four levels: Very Hard, Hard, Medium, Easy\n",
    "            self.class_labels = [\"v\", \"h\", \"m\", \"e\"]  # very hard, hard, medium, easy\n",
    "            self.class_names = [\"Very Hard\", \"Hard\", \"Medium\", \"Easy\"]\n",
    "        else:\n",
    "            raise ValueError(f\"num_classes must be 2, 3, or 4, got {num_classes}\")\n",
    "\n",
    "        # Pre-tokenize difficulty level labels with space prefix\n",
    "        self.class_ids = []\n",
    "        for label in self.class_labels:\n",
    "            label_text = f\" {label}\"\n",
    "            ids = self.tokenizer(label_text, add_special_tokens=False).input_ids\n",
    "            if len(ids) == 0:\n",
    "                raise ValueError(f\"Tokenizer produced empty ids for label '{label}'\")\n",
    "            self.class_ids.append(ids)\n",
    "\n",
    "        # Check if all labels tokenize to single tokens\n",
    "        self.single_token_labels = all(len(ids) == 1 for ids in self.class_ids)\n",
    "        if self.single_token_labels:\n",
    "            self.class_token_ids = [ids[0] for ids in self.class_ids]\n",
    "\n",
    "    def build_prompt(self, question: str) -> str:\n",
    "        \"\"\"Build the difficulty prediction prompt.\"\"\"\n",
    "        if self.num_classes == 2:\n",
    "            instruction = \"Is this math question as h (hard) or e (easy)? Answer with one character, h or e. \"\n",
    "        elif self.num_classes == 3:\n",
    "            instruction = \"Is this math question as h (hard), m (medium), or e (easy)? Answer with one character, h, m or e.\"\n",
    "        elif self.num_classes == 4:\n",
    "            instruction = \"Is this math question as v (very hard), h (hard), m (medium), or e (easy). Answer with one character, v, h, m or e. \"\n",
    "\n",
    "        prompt = (\n",
    "            f\"Question: {question}\\n\\n\"\n",
    "            f\"{instruction}\\n\\n\"\n",
    "\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def _forward(self, question: str, compute_gradients: bool = False):\n",
    "            \"\"\"\n",
    "            Internal forward pass that can optionally compute gradients.\n",
    "            \"\"\"\n",
    "            # 1. Prepare Prompt\n",
    "            prompt = self.build_prompt(question)\n",
    "            context_enc = self.tokenizer(prompt, add_special_tokens=True)\n",
    "            context_ids = context_enc.input_ids\n",
    "\n",
    "            device = self.model.device\n",
    "            ctx_tensor = torch.tensor(context_ids, dtype=torch.long, device=device)\n",
    "\n",
    "            # 2. Create sequences for each class\n",
    "            sequences = []\n",
    "            for class_token_ids in self.class_ids:\n",
    "                label_tensor = torch.tensor(class_token_ids, dtype=torch.long, device=device)\n",
    "                seq = torch.cat([ctx_tensor, label_tensor])\n",
    "                sequences.append(seq)\n",
    "\n",
    "            # 3. Batch and pad\n",
    "            pad_val = self.tokenizer.pad_token_id if self.tokenizer.pad_token_id is not None else self.tokenizer.eos_token_id\n",
    "            input_ids = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=pad_val)\n",
    "            attention_mask = (input_ids != pad_val).long()\n",
    "\n",
    "            # 4. Forward pass (with or without gradients)\n",
    "            if compute_gradients:\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            logits = outputs.logits\n",
    "            log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "            # 5. Extract log probabilities\n",
    "            class_log_probs = []\n",
    "            for batch_idx, label_ids in enumerate(self.class_ids):\n",
    "                start_pos = len(context_ids)\n",
    "                end_pos = start_pos + len(label_ids)\n",
    "                total_logprob = 0.0\n",
    "\n",
    "                for pos in range(start_pos, end_pos):\n",
    "                    target_token_id = input_ids[batch_idx, pos].item()\n",
    "                    token_logprob = log_probs[batch_idx, pos - 1, target_token_id]\n",
    "                    if not compute_gradients:\n",
    "                        token_logprob = token_logprob.item()\n",
    "                    total_logprob += token_logprob\n",
    "\n",
    "                class_log_probs.append(total_logprob)\n",
    "\n",
    "            # 6. Convert to tensor\n",
    "            if compute_gradients:\n",
    "                class_log_probs = torch.stack(class_log_probs)\n",
    "            else:\n",
    "                class_log_probs = torch.tensor(class_log_probs, device=device)\n",
    "\n",
    "            return class_log_probs\n",
    "\n",
    "    def predict(self, question: str) -> dict:\n",
    "        \"\"\"\n",
    "        Return difficulty prediction as probability distribution over classes.\n",
    "        Uses no_grad for inference.\n",
    "        \"\"\"\n",
    "        class_log_probs = self._forward(question, compute_gradients=False)\n",
    "        class_probs = F.softmax(class_log_probs, dim=0)\n",
    "        predicted_class = class_probs.argmax().item()\n",
    "\n",
    "        return {\n",
    "            'probabilities': class_probs,\n",
    "            'predicted_class': predicted_class,\n",
    "            'predicted_label': self.class_labels[predicted_class],\n",
    "            'predicted_name': self.class_names[predicted_class],\n",
    "            'log_probs': class_log_probs\n",
    "        }\n",
    "\n",
    "    def compute_loss(self, question: str, true_class: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Compute cross-entropy loss for training.\n",
    "        Enables gradient computation.\n",
    "        \"\"\"\n",
    "        class_log_probs = self._forward(question, compute_gradients=True)\n",
    "\n",
    "        # Cross-entropy loss: -log P(true_class)\n",
    "        loss = -class_log_probs[true_class]\n",
    "\n",
    "        # Also return prediction for tracking accuracy\n",
    "        with torch.no_grad():\n",
    "            class_probs = F.softmax(class_log_probs, dim=0)\n",
    "            pred_class = class_probs.argmax().item()\n",
    "\n",
    "        return loss, pred_class\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# Initialize classifier\n",
    "classifier = MathDifficultyClassifier(\n",
    "    model_name=\"Qwen/Qwen2.5-0.5B\",\n",
    "    device=torch.device(\"cuda\"),\n",
    "    num_classes=4\n",
    ")\n",
    "\n",
    "# Predict difficulty\n",
    "question = \"What is 2 + 2?\"\n",
    "result = classifier.predict(question)\n",
    "print(f\"Predicted difficulty level: {result['predicted_level']}\")\n",
    "print(f\"Class probabilities: {result['probabilities']}\")\n",
    "\n",
    "# Compute loss for training\n",
    "true_class = 0  # This is an easy question (class 0 = level 1)\n",
    "loss, pred = classifier.compute_loss(question, true_class)\n",
    "print(f\"Loss: {loss:.4f}, Predicted: {pred}, True: {true_class}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Test Pre-Finetuned Classification Capacity (with model output)\n",
    "# ==============================================================================\n",
    "# Goal: Evaluate zero-shot performance and check if model follows instructions\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Testing Pre-Finetuned Model on Difficulty Classification\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "NUM_CLASSES = 3\n",
    "TEST_SAMPLES = 1 # Number of samples to test\n",
    "\n",
    "# Load dataset\n",
    "print(\"\\n✓ Loading dataset...\")\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_questions = json.load(f)\n",
    "\n",
    "# Create test dataset (use validation split)\n",
    "random.seed(42)\n",
    "random.shuffle(raw_questions)\n",
    "split_idx = int(0.9 * len(raw_questions))\n",
    "val_questions = raw_questions[split_idx:split_idx + TEST_SAMPLES]\n",
    "\n",
    "test_dataset = DifficultyClassificationDataset(\n",
    "    val_questions,\n",
    "    tokenizer,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "print(f\"✓ Test dataset loaded: {len(test_dataset)} samples\")\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = MathDifficultyClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    device=device,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "print(f\"✓ Classifier initialized: {NUM_CLASSES} classes\")\n",
    "print(f\"✓ Class labels: {classifier.class_labels}\")\n",
    "print(f\"✓ Class names: {classifier.class_names}\")\n",
    "print(f\"✓ Single token labels: {classifier.single_token_labels}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Helper function to generate actual model output\n",
    "def get_model_generation(question, max_new_tokens=10):\n",
    "    \"\"\"Generate text to see what model actually outputs\"\"\"\n",
    "    prompt = classifier.build_prompt(question)\n",
    "    print(f\"prompt{prompt}\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,  # Greedy decoding\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode only the generated part (skip prompt)\n",
    "    generated_ids = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_text.strip()\n",
    "\n",
    "# Evaluate on test samples\n",
    "predictions = []\n",
    "true_labels = []\n",
    "correct = 0\n",
    "\n",
    "print(\"\\nEvaluating samples...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for idx in range(min(TEST_SAMPLES, len(test_dataset))):\n",
    "    # Get sample\n",
    "    sample = test_dataset.samples[idx]\n",
    "    question = val_questions[idx]['question']\n",
    "    true_class = sample['label']  # 0-indexed\n",
    "    true_prob = sample['prob']  # Original probability\n",
    "\n",
    "    # Predict using probability method\n",
    "    result = classifier.predict(question)\n",
    "    pred_class = result['predicted_class']\n",
    "    pred_label = result['predicted_label']\n",
    "    pred_name = result['predicted_name']\n",
    "\n",
    "    # Generate actual model output\n",
    "    generated_answer = get_model_generation(question)\n",
    "\n",
    "    predictions.append(pred_class)\n",
    "    true_labels.append(true_class)\n",
    "\n",
    "    is_correct = (pred_class == true_class)\n",
    "    correct += is_correct\n",
    "\n",
    "    # Print samples in detail\n",
    "\n",
    "    print(f\"\\nSample {idx + 1}:\")\n",
    "    print(f\"  Question: {question}\")\n",
    "    print(f\"  True: Class {true_class} ({classifier.class_names[true_class]}) | Prob: {true_prob:.3f}\")\n",
    "    print(f\"  Pred: Class {pred_class} ({pred_name}) | Label: '{pred_label}' | Confidence: {result['probabilities'][pred_class].item():.3f}\")\n",
    "    print(f\"  Model Output: '{generated_answer}'\")\n",
    "    print(f\"  Full distribution: {dict(zip(classifier.class_names, [f'{p:.3f}' for p in result['probabilities'].tolist()]))}\")\n",
    "    print(f\"  Result: {'✓ CORRECT' if is_correct else '✗ WRONG'}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = correct / len(predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(predictions)}\")\n",
    "print(f\"Correct predictions: {correct}\")\n",
    "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Confusion analysis\n",
    "print(f\"\\nClass Distribution:\")\n",
    "for class_idx in range(NUM_CLASSES):\n",
    "    true_count = true_labels.count(class_idx)\n",
    "    pred_count = predictions.count(class_idx)\n",
    "    print(f\"  {classifier.class_names[class_idx]} ({classifier.class_labels[class_idx]}): True={true_count}, Predicted={pred_count}\")\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "print(f\"\\nPer-Class Accuracy:\")\n",
    "for class_idx in range(NUM_CLASSES):\n",
    "    true_positives = sum(1 for t, p in zip(true_labels, predictions) if t == class_idx and p == class_idx)\n",
    "    total_true = true_labels.count(class_idx)\n",
    "    if total_true > 0:\n",
    "        class_acc = true_positives / total_true\n",
    "        print(f\"  {classifier.class_names[class_idx]}: {class_acc:.4f} ({true_positives}/{total_true})\")\n",
    "    else:\n",
    "        print(f\"  {classifier.class_names[class_idx]}: N/A (no samples)\")\n",
    "\n",
    "# Random baseline\n",
    "random_accuracy = 1.0 / NUM_CLASSES\n",
    "print(f\"\\nRandom baseline: {random_accuracy:.4f} ({random_accuracy*100:.2f}%)\")\n",
    "print(f\"Model improvement: {(accuracy - random_accuracy)*100:.2f} percentage points\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Pre-Finetuned Evaluation Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7578c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actual model output\n",
    "question = val_questions[5]['question']\n",
    "# answer = val_questions[2]['answers'][0]\n",
    "# prompt = (\n",
    "#     f\"Question: {question}\\n\"\n",
    "#     f\"Is this answer correct? Answer y(yes) or n(no).\"\n",
    "# )\n",
    "n = 2\n",
    "# instruction = \"Is this question easy or difficult? Answer E(easy) or D(difficult).\"\n",
    "if n == 2:\n",
    "    instruction = \"Rate this math question as h (hard) or e (easy).\"\n",
    "elif n == 3:\n",
    "    instruction = \"Rate this math question as h (hard), m (medium), or e (easy).\"\n",
    "elif n == 4:\n",
    "    instruction = \"Rate this math question as v (very hard), h (hard), m (medium), or e (easy).\"\n",
    "prompt = (\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"{instruction}\\n\\n\"\n",
    ")\n",
    "# Helper function to generate actual model output\n",
    "def get_model_result(prompt, max_new_tokens=10):\n",
    "    \"\"\"Generate text to see what model actually outputs\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,  # Greedy decoding\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decode only the generated part (skip prompt)\n",
    "    generated_ids = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_text.strip()\n",
    "generated_answer = get_model_result(prompt)\n",
    "print(f\"question: {question}, answer: {answer}, model_response: {generated_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f42b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Training Loop: Difficulty Classification with Letter Labels\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 1  # Process one question at a time due to special forward pass\n",
    "DEBUG_SAMPLE_SIZE = None  # Use small subset for quick testing\n",
    "\n",
    "# Load and prepare dataset\n",
    "print(\"\\n✓ Loading dataset...\")\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_questions = json.load(f)\n",
    "\n",
    "if DEBUG_SAMPLE_SIZE:\n",
    "    raw_questions = raw_questions[:DEBUG_SAMPLE_SIZE]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(raw_questions)\n",
    "split_idx = int(0.9 * len(raw_questions))\n",
    "train_questions = raw_questions[:split_idx]\n",
    "val_questions = raw_questions[split_idx:]\n",
    "\n",
    "train_dataset = DifficultyClassificationDataset(train_questions, tokenizer, num_classes=NUM_CLASSES, max_length=256)\n",
    "val_dataset = DifficultyClassificationDataset(val_questions, tokenizer, num_classes=NUM_CLASSES, max_length=256)\n",
    "\n",
    "print(f\"✓ Dataset loaded: {len(train_dataset)} train, {len(val_dataset)} val samples\")\n",
    "\n",
    "# Initialize classifier and optimizer\n",
    "classifier = MathDifficultyClassifier(MODEL_NAME, device, num_classes=NUM_CLASSES)\n",
    "optimizer = torch.optim.AdamW(classifier.model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Learning rate scheduler\n",
    "total_steps = len(train_dataset) * EPOCHS\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=0.1,\n",
    "    end_factor=1.0,\n",
    "    total_iters=warmup_steps\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training setup:\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Classes: {NUM_CLASSES} ({', '.join(classifier.class_names)})\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "\n",
    "# Training loop\n",
    "best_val_acc = 0.0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ==================== Training ====================\n",
    "    classifier.model.train()\n",
    "    epoch_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    progress_bar = tqdm(range(len(train_dataset)), desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
    "\n",
    "    for idx in progress_bar:\n",
    "        # Get sample\n",
    "        sample = train_dataset.samples[idx]\n",
    "        question = train_questions[idx]['question']\n",
    "        true_class = sample['label']\n",
    "\n",
    "        # Compute loss\n",
    "        loss, pred_class = classifier.compute_loss(question, true_class)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx < warmup_steps:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Track metrics\n",
    "        epoch_loss += loss.item()\n",
    "        train_correct += (pred_class == true_class)\n",
    "\n",
    "        # Update progress bar\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{epoch_loss/(idx+1):.4f}',\n",
    "                'acc': f'{train_correct/(idx+1):.4f}'\n",
    "            })\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_dataset)\n",
    "    train_acc = train_correct / len(train_dataset)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ==================== Validation ====================\n",
    "    classifier.model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in tqdm(range(len(val_dataset)), desc=f\"Epoch {epoch+1}/{EPOCHS} [Val]  \", leave=False):\n",
    "            sample = val_dataset.samples[idx]\n",
    "            question = val_questions[idx]['question']\n",
    "            true_class = sample['label']\n",
    "\n",
    "            # Compute loss\n",
    "            loss, pred_class = classifier.compute_loss(question, true_class)\n",
    "            val_loss += loss.item()\n",
    "            val_correct += (pred_class == true_class)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataset)\n",
    "    val_acc = val_correct / len(val_dataset)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} Summary:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        # Save model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': classifier.model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "        }, 'best_difficulty_classifier.pt')\n",
    "        print(f\"  ✓ New best validation accuracy: {best_val_acc:.4f} - Model saved!\")\n",
    "\n",
    "    print(\"-\"*60)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Random Baseline: {1.0/NUM_CLASSES:.4f}\")\n",
    "print(f\"Improvement: {(best_val_acc - 1.0/NUM_CLASSES)*100:.2f} percentage points\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-verifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
